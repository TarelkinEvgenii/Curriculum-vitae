{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Я вижу 2 способа решения этой задачи:\n",
    "1. Взять наиболее значимые признаки вычисленные при помощи бутстрапа или статистических критериев других и в 3 экспериментировать с этими колонками\n",
    "2. Взять уже обученный на всём трейне катбуст и взять из него 3 самых значимых столбца и взять из них границы и использовать их как правило антифрода"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Решил делать с катбустом\n",
    "with open(\"../src/app/core/catboost_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Загрузим трейн датасет, полученный в hw4\n",
    "data = pd.read_csv('../src/app/core/train_X.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(model.get_feature_importance(), columns=['importance'])\n",
    "border = pd.DataFrame(model.get_borders().values())\n",
    "feature_names = list(data.columns)\n",
    "feature_names.remove('SK_ID_CURR')\n",
    "feature_names.remove('TARGET')\n",
    "feature_names = pd.DataFrame(feature_names, columns=['name'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                  name  importance             0         1         2  \\\n0  WEIGHTED_EXT_SOURCE    6.434536 -3.402823e+38  0.120988  0.129951   \n1     INTEREST_RATE_v1    3.736829  2.923760e-02  0.029240  0.029330   \n2           DEBT_RATIO    3.036217  1.262867e-01  0.498487  0.517171   \n\n          3         4         5         6         7  ...        46        47  \\\n0  0.168538  0.174112  0.190508  0.200611  0.205222  ...  0.594225  0.642128   \n1  0.029340  0.029664  0.030572  0.031496  0.032255  ...       NaN       NaN   \n2  0.539629  0.541906  0.580905  0.587385  0.606625  ...  0.956937  0.975938   \n\n         48        49        50        51        52        53        54  \\\n0  0.666649  0.696929  0.699536  0.736625  0.741814       NaN       NaN   \n1       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n2  0.986005  0.992775  0.996735  1.001551  1.009983  1.068054  1.313749   \n\n         55  \n0       NaN  \n1       NaN  \n2  1.591746  \n\n[3 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>importance</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WEIGHTED_EXT_SOURCE</td>\n      <td>6.434536</td>\n      <td>-3.402823e+38</td>\n      <td>0.120988</td>\n      <td>0.129951</td>\n      <td>0.168538</td>\n      <td>0.174112</td>\n      <td>0.190508</td>\n      <td>0.200611</td>\n      <td>0.205222</td>\n      <td>...</td>\n      <td>0.594225</td>\n      <td>0.642128</td>\n      <td>0.666649</td>\n      <td>0.696929</td>\n      <td>0.699536</td>\n      <td>0.736625</td>\n      <td>0.741814</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>INTEREST_RATE_v1</td>\n      <td>3.736829</td>\n      <td>2.923760e-02</td>\n      <td>0.029240</td>\n      <td>0.029330</td>\n      <td>0.029340</td>\n      <td>0.029664</td>\n      <td>0.030572</td>\n      <td>0.031496</td>\n      <td>0.032255</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DEBT_RATIO</td>\n      <td>3.036217</td>\n      <td>1.262867e-01</td>\n      <td>0.498487</td>\n      <td>0.517171</td>\n      <td>0.539629</td>\n      <td>0.541906</td>\n      <td>0.580905</td>\n      <td>0.587385</td>\n      <td>0.606625</td>\n      <td>...</td>\n      <td>0.956937</td>\n      <td>0.975938</td>\n      <td>0.986005</td>\n      <td>0.992775</td>\n      <td>0.996735</td>\n      <td>1.001551</td>\n      <td>1.009983</td>\n      <td>1.068054</td>\n      <td>1.313749</td>\n      <td>1.591746</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Объединим таблицы и отсортируем их по важности фичи\n",
    "data_for_rules = pd.concat([feature_names, feature_importance, border], axis=1).sort_values(\n",
    "    'importance', ascending=False).reset_index(drop=True)\n",
    "data_for_rules.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def check_target(testing_data: pd.DataFrame) -> float:\n",
    "    '''Функция выдающая процент TARGET в выборке'''\n",
    "    return testing_data['TARGET'].value_counts()[1] / len(testing_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08486411000107423%\n"
     ]
    }
   ],
   "source": [
    "# Выведем процент фрода во всём датасете\n",
    "print(f'{check_target(data)}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTED_EXT_SOURCE lt 0.12098759412765503 with result 0.2600297176820208%\n",
      "INTEREST_RATE_v1 ge 0.10916344821453094 with result 0.08717948717948718%\n",
      "DEBT_RATIO ge 1.313748836517334 with result 0.17358490566037735%\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from operator import lt, le, ge, gt\n",
    "\n",
    "\n",
    "def get_best_rule(rule: pd.Series, data_for_testing: pd.DataFrame) -> Tuple[str, str, float, float]:\n",
    "    \"\"\"Функция берёт правило и датасет и ищет наилучшее правило\"\"\"\n",
    "    rule = pd.DataFrame(rule)\n",
    "    # <,<=,>=,>\n",
    "    operators = [lt, le, ge, gt]\n",
    "    best_operator = None\n",
    "    best_value = None\n",
    "    best_result = 0\n",
    "    for operator in operators:\n",
    "        for i in range(len(rule) - 3):\n",
    "            if best_operator is None and best_value is None:\n",
    "                best_operator = operator\n",
    "                best_value = rule.loc[i]\n",
    "            if np.isnan(float(rule.loc[i])):\n",
    "                break\n",
    "            index = pd.Series(np.array(operator(data_for_testing[rule.loc['name']],\n",
    "                                                float(rule.loc[i]))\n",
    "                                       )[:, 0])\n",
    "\n",
    "            test_data = data_for_testing.loc[index]\n",
    "            if len(test_data) != 0:\n",
    "                result = check_target(test_data)\n",
    "                # Так как нельзя больше 5% данных брать\n",
    "                if index.value_counts()[1] / len(index) < 0.05:\n",
    "                    if result > best_result:\n",
    "                        best_operator = operator\n",
    "                        best_value = rule.loc[i]\n",
    "                        best_result = result\n",
    "\n",
    "    return np.array(rule.loc['name'])[0], best_operator, float(best_value), best_result\n",
    "\n",
    "\n",
    "# Получим все лучшие правила\n",
    "name, operation, value, result = get_best_rule(data_for_rules.iloc[0], data)\n",
    "print(f'{name} {operation.__name__} {value} with result {result}%')\n",
    "\n",
    "name2, operation2, value2, result2 = get_best_rule(data_for_rules.iloc[1], data)\n",
    "print(f'{name2} {operation2.__name__} {value2} with result {result2}%')\n",
    "\n",
    "name3, operation3, value3, result3 = get_best_rule(data_for_rules.iloc[2], data)\n",
    "print(f'{name3} {operation3.__name__} {value3} with result {result3}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как мы видим правила антифрода убирают большой процент фрода\n",
    "1. 26% фрода при WEIGHTED_EXT_SOURCE < 0.12098759412765503\n",
    "2. 8.7% фрода при INTEREST_RATE_v1 >= 0.10916344821453094\n",
    "3. 17.3% фрода при DEBT_RATIO >= 1.313748836517334\n",
    "\n",
    "В теории можно перебрать все столбцы и их значения из обученного катбуста, но я не стал, так как это вычислительно сложно и будет долго считать"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Надо чтобы равномерно было в каждом датасете таргетов\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "my_cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "folds = pd.DataFrame(my_cv.split(data, np.array(data['TARGET']).ravel()))[1]\n",
    "train_indicies = np.concatenate([folds[0], folds[1], folds[2], folds[3]])\n",
    "val_indicies = folds[4]\n",
    "\n",
    "train = data.iloc[train_indicies].reset_index(drop=True)\n",
    "validation = data.iloc[val_indicies].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Применим правила\n",
    "def apply_rules(data_for_rules: pd.DataFrame, names: list, operations: list,\n",
    "                values: list) -> pd.DataFrame:\n",
    "    assert len(names) == len(operations)\n",
    "    assert len(operations) == len(values)\n",
    "    for i in range(len(names)):\n",
    "        if i == 0:\n",
    "            my_operation = operations[i]\n",
    "            index = np.array(my_operation(data_for_rules[names[i]],\n",
    "                                          float(values[i]))\n",
    "                             )\n",
    "            # Инвертируем индекс, чтобы не брать фродовые случаи\n",
    "            index = ~index\n",
    "        else:\n",
    "            my_operation = operations[i]\n",
    "            index = np.logical_and(index, ~np.array(my_operation(data_for_rules[names[i]],\n",
    "                                                                 float(values[i]))))\n",
    "    return data_for_rules[pd.Series(index)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_after_rule = apply_rules(train,\n",
    "                               [name, name2, name3],\n",
    "                               [operation, operation2, operation3],\n",
    "                               [value, value2, value3])\n",
    "\n",
    "validation_after_rule = apply_rules(validation,\n",
    "                                    [name, name2, name3],\n",
    "                                    [operation, operation2, operation3],\n",
    "                                    [value, value2, value3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7496935268533778\n",
      "0.7496935268533778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ctbst = CatBoostClassifier(depth=8,\n",
    "                           l2_leaf_reg=10,\n",
    "                           silent=True,\n",
    "                           border_count=254)\n",
    "feature_names = list(data.columns)\n",
    "feature_names.remove('SK_ID_CURR')\n",
    "feature_names.remove('TARGET')\n",
    "\n",
    "train_Y = np.array(train_after_rule['TARGET'])\n",
    "train_X = train_after_rule[feature_names]\n",
    "\n",
    "val_Y = np.array(validation_after_rule['TARGET'])\n",
    "val_X = validation_after_rule[feature_names]\n",
    "\n",
    "ctbst.fit(train_X, train_Y)\n",
    "preds = ctbst.predict_proba(val_X)[:, 1]\n",
    "print(roc_auc_score(val_Y, preds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "roc_auc стал 0.7496 - это лучше, чем без правил антифрода, без правил модель предсказывала roc_auc_score=0.7491\n",
    "\n",
    "Правила сформированы более менее нормально и выделяют больший процент фрода, чем есть в процент фрода в датасете"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
